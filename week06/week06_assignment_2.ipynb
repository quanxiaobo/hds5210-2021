{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 6 Exercises\n",
    "\n",
    "_McKinney 6.1_\n",
    "\n",
    "There are multiple ways to solve the problems below.  You can use any one of several approaches.  For example, you can read CSV files using Pandas or the csv module.  Your score won't depend on which modules you choose to use unless explicitly noted below, but your programming style will still matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 30.1 List of Allergies\n",
    "\n",
    "In the /data directory on the Jupyter server, there is a file called `allergies.json` that contains a list of patient allergies.  It is taken from sample data provided by the EHR vendor, Epic, here: https://open.epic.com/Clinical/Allergy\n",
    "\n",
    "Take some time to look at the structure of the file.  You can open it directly in Jupyter by clicking the _Home_ icon, then the _from_instructor_ folder, and then the _data_ folder.\n",
    "\n",
    "Within the file, you'll see that it is a dictionary with many items in it.  One of those items is called `entry` and that item is a list of things.  You can tell that because the item name is immediately followed by an opening square bracket, signifying the start of a list.  It's line 11 of the file: `  \"entry\": [`\n",
    "\n",
    "Write a function named `allergy_count(json_file)` that takes as one parameter the name of the JSON file and returns an integer number of entries in that file.  Your function should open the file, read the json into a Python object, and return how many items there are in the list of `entry`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "ALLERGIES_FILE=\"/data/allergies.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def allergy_count(json_file):\n",
    "    \"\"\"(str)->int\n",
    "    This function takes a JSON file name. It assumes that the file contains \n",
    "    a dictionary with one or several key(s) of 'entry' with information about \n",
    "    patient allergies. \n",
    "    \n",
    "    This function reads the file and returns the count of entries (i.e. # of allergies). \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    return(len(allergies.get('entry')))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allergy_count(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q1-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(allergy_count(ALLERGIES_FILE)) == int\n",
    "assert allergy_count(ALLERGIES_FILE) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30.2 Number of Patients\n",
    "\n",
    "If you dig a little bit deaper into this list of allergies, you'll see that each result has a patient associated with it.  Create a funcation called `patient_count(json_file)` that will count how many unique patients we have in this JSON structure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def patient_count(json_file):\n",
    "    \"\"\"(str)->int\n",
    "    This function takes a JSON file name. It assumes that the file contains \n",
    "    a dictionary with one or several key(s) of 'entry' with information about \n",
    "    patient allergies including patient names. \n",
    "    \n",
    "    This function reads the file and returns the count of unique patients who \n",
    "    have allergies. \n",
    "    \"\"\"\n",
    "        \n",
    "    patients = set()\n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    for entry in allergies.get('entry'):\n",
    "        resource = entry.get('resource')\n",
    "        patient = resource.get('patient')\n",
    "        name = patient.get('display')\n",
    "        patients.add(name)\n",
    "        \n",
    "    return patients\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jason Argonaut', 'Paul Boal'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_count(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30.3 How Many Allergies per Patient\n",
    "\n",
    "Although each entry is a separate allergy, several of them are for the same patient.  Write a function called `allergy_per_patient(json_file)` that counts up how many allergies each patient has.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def allergy_per_patient(json_file):\n",
    "    \"\"\"(str)->dict\n",
    "    This function takes a JSON file name. It assumes that the file contains \n",
    "    a dictionary with one or several key(s) of 'entry' with information about \n",
    "    patient allergies including patient names. \n",
    "    \n",
    "    This function reads the file and returns a dictionary with number of allergies \n",
    "    (as value) for each patient (as key). \n",
    "    \"\"\"\n",
    "    patients = {}\n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    for entry in allergies.get('entry'):\n",
    "        resource = entry.get('resource')\n",
    "        patient = resource.get('patient')\n",
    "        name = patient.get('display')\n",
    "        patients[name] = patients.setdefault(name,0) + 1\n",
    "        \n",
    "    return patients\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jason Argonaut': 3, 'Paul Boal': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allergy_per_patient(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-question",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 30.4 Patient Allergies and Reaction\n",
    "\n",
    "You'll see in the file that each of the items in the `entry` list have several other attributes including a patient name, substance text representation, and a reaction manifestation.  Create a function named `allergy_list(json_file)` that will create an output list that has patient name, allergy, and reaction for each `entry`.  The actual result you should get will be:\n",
    "\n",
    "```python\n",
    "[['Jason Argonaut', 'PENICILLIN G', 'Hives'],\n",
    " ['Paul Boal', 'PENICILLIN G', 'Bruising'],\n",
    " ['Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS', 'Itching'],\n",
    " ['Jason Argonaut', 'STRAWBERRY', 'Anaphylaxis']]\n",
    "```\n",
    "\n",
    "You'll notice that the reaction and the manifestation of that action are lists.  You only need to capture the first reaction and the first manifestation of the action.  That is, if there is a list of things, just output the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "def allergy_list(json_file):\n",
    "    \"\"\"(str)->list\n",
    "    This function takes a JSON file name. It assumes that the file contains \n",
    "    a dictionary with one or several key(s) of 'entry' with information about \n",
    "    patient allergies including patient names, allergies, and reactions. \n",
    "    \n",
    "    This function reads the file and returns a list with patient name, allergy,\n",
    "    and the first reaction for each entry. \n",
    "    \"\"\"\n",
    "    patients = []\n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    for entry in allergies.get('entry'):\n",
    "        patient = entry.get('resource').get('patient').get('display')\n",
    "        substance = entry.get('resource').get('substance').get('text')\n",
    "        reaction = entry.get('resource').get('reaction')[0].get('manifestation')[0].get('text')\n",
    "        patients.append([patient, substance, reaction])\n",
    "        \n",
    "    return patients\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q2-tests",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "output=[['Jason Argonaut', 'PENICILLIN G', 'Hives'],\n",
    " ['Paul Boal', 'PENICILLIN G', 'Bruising'],\n",
    " ['Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS', 'Itching'],\n",
    " ['Jason Argonaut', 'STRAWBERRY', 'Anaphylaxis']]\n",
    "\n",
    "assert allergy_list(ALLERGIES_FILE) == output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3-question",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 30.5 Allergy Reaction\n",
    "\n",
    "Write a function called `allergy_reaction(json_file,patient,substance)` that takes three parameter and returns the reaction that will happen if the patient takes the specified substance.  Solve this, in part, by calling your `allergy_list` function inside your new `allergy_reaction` function.\n",
    "\n",
    "If the substance is not found in the allergy list, the function should return None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "def allergy_reaction(json_file,patient,substance):\n",
    "    \"\"\"(str, str, str)->str\n",
    "    This function takes a JSON file name, a patient name, and a substance name. \n",
    "    It assumes that the file contains a dictionary with one or several key(s) \n",
    "    of 'entry' with information about patient allergies including \n",
    "    patient names, allergies, and reactions. \n",
    "    \n",
    "    This function reads the file and utilizes the allergy_list function to return \n",
    "    the reaction that will happen if the patient takes the specified substance. \n",
    "    \n",
    "    The function returns None if the specific substance or patient is not in the\n",
    "    allergy list.\n",
    "    \"\"\"\n",
    "    allergies = allergy_list(json_file)\n",
    "    reaction = None\n",
    "    for allergy in allergies:\n",
    "        if allergy[0:2] == [patient, substance]:\n",
    "            reaction = allergy[2]\n",
    "    return reaction\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q3-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'PENICILLIN G') == 'Hives'\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS') == 'Itching'\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'STRAWBERRY') == 'Anaphylaxis'\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'PENICILLIN') == None\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Paul Boal', 'PENICILLIN G') == 'Bruising'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Stretch (Extra) Problems\n",
    "\n",
    "Work on either of the stretch problems below can earn you up to 25 free points toward the midterm assignment.  That is, if you complete one of these extra problems successfully, you can skip 1 of the problems that will appear on the midterm exam coming up next week.\n",
    "\n",
    "The midterm will be distribute this Saturday 3/13.\n",
    "\n",
    "This assignment is due on Sunday 3/14.  If you are trying for one of these extra problems Slack me, and I'll provide you feedback on how you did on these before end of day Monday 3/15.  That way you can choose what to complete on the midterm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### STRETCH for March 2021 - For those looking for an additional challenge\n",
    "\n",
    "As I've mentioned in class, CMS is now enforcing a rule around price transparency.  Every facility that take Medicare payments is required to publish a \"machine readable\" file with it's pricing infomration for a number of common procedures across all of the payers they work with.  There are two examples of such files in the `/data/` directory: `whiteriver.json` and `saline.xml`.\n",
    "\n",
    "If you want to compare contracted prices across these two hospitals, you'll need to read in the information from both of those files into some kind of data structure, then merge the data together from those two files.  See what you can do.\n",
    "\n",
    "See if you can create an output file that has the following fields:\n",
    "* HOSPITAL\n",
    "* PROCEDURE_CODE\n",
    "* PAYER\n",
    "* AMOUNT\n",
    "\n",
    "If you choose to work on this, you may get stuck at some point and you won't know if you're _doing it right_. Make some assumptions. Document your questions in this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of contracted prices. \n",
    "# Each indiciual price is a list including hospital name, procedire_code, payer, and amount.\n",
    "# This list of lists can be write to csv file or converted to DataFrame in pandas.\n",
    "\n",
    "# Step-1: create a list from the json file\n",
    "import json\n",
    "prices1 = []\n",
    "whiteriver_json=\"/data/whiteriver.json\"\n",
    "with open(whiteriver_json) as f:\n",
    "    wrcharges = json.load(f)\n",
    "hospital = wrcharges.get('root').get('HospitalorFacilityName')\n",
    "excluded_payer_list = ['Description','ProcedureCode','Modifier','RevenueCode','MSDRG',\n",
    "                       'NDC','InpatientGrossCharge','OutpatientGrossCharge',\n",
    "                       'EmergencyRoomGrossCharge','MSDRGAverageGrossCharge',\n",
    "                       'DiscountedCashPrice','MinimumNegotiatedCharge',\n",
    "                       'MaximumNegotiatedCharge']\n",
    "for procedure in wrcharges.get('root').get('StandardCharges'):\n",
    "    procedure_code = procedure.get('ProcedureCode')\n",
    "    for payer, charge in procedure.items():\n",
    "        if payer not in excluded_payer_list:\n",
    "            prices1.append([hospital, procedure_code, payer, round(float(charge), 2)])\n",
    "\n",
    "# Step-2: create a list from the xml file\n",
    "import xml.etree.ElementTree as ET\n",
    "prices2=[]\n",
    "saline_xml=\"/data/saline.xml\"\n",
    "with open(saline_xml) as f:\n",
    "    tree = ET.parse(f)\n",
    "root = tree.getroot()\n",
    "for facility in root.iter('Facility'):\n",
    "    hospital = facility.get('Name').title()\n",
    "    for patient in root.iter('Patient'):\n",
    "        patient_type = patient.get('Type')\n",
    "        for charge in patient.iter('Charge'):\n",
    "            charge_type = charge.get('Type')\n",
    "            if charge_type == 'HCPCS':\n",
    "                for item in charge.iter('Item'):\n",
    "                    procedure_code = item.get('Code')\n",
    "                    for contracts in item.iter('Contracts'):\n",
    "                        for contract in contracts.iter('Contract'):\n",
    "                            payer = contract.get('Payer').replace(\" \", \"\")+'_'+patient_type\n",
    "                            amount = round(float(contract.get('Charge')), 2)\n",
    "                            prices2.append([hospital, procedure_code, payer, amount])\n",
    "\n",
    "# Step-3: combine the two lists\n",
    "prices = prices1 + prices2\n",
    "import csv\n",
    "with open(\"output.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Hospital','Procedure_code','Payer','Amount'])\n",
    "    writer.writerows(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question: How can the payer names from different sources be automatically revised so that they are consistent across the list? \n",
    "### The payer names are formatted differntly in the two files. \n",
    "### Ideally one particular payer should have a same name across the list. \n",
    "### Perhaps the payer names should be converted to payer codes, assuming a unique payer code exsist for an indivisual payer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### STRETCH from March 2020 - For those looking for an additional challenge\n",
    "\n",
    "The Coronavirus is creating quite the stir right now.  There are some sources suggesting that trends show it is going to be significantly more serious than SARS was back in the 2002 timeframe.  Here's one visualization trying to demonstrate that: https://www.reddit.com/r/China_Flu/comments/ev2b4v/i_updated_some_charts_comparing_this_outbreak/\n",
    "\n",
    "Someone on Kaggle has generously already compiled a dataset based on information from Johns Hopkins about the Coronavirus outbreak.  https://www.kaggle.com/brendaso/2019-coronavirus-dataset-01212020-01262020  Create a Kaggle account, if you don't already have one.  Download this data set and then upload it to your Jupyter Home folder.  (The \"up arrow\" button is for uploading a file.)\n",
    "\n",
    "Use Python's built-in `csv` module to read the data from this file and generate the following information: **what are the total confirmed cases in all of Mainland China as of the latest information in the data set?**  Some important things to note:\n",
    "* Each entry for a given city has the **cumulative** number of cases.  So that column is not additive (it cannot be summed).  You'll have to find a way to filter your data for the last day for each city, then total those up.\n",
    "* If you choose to parse the date column, you will want to lookup how to do that using Python's `datetime` module.  Especially the `strptime` function.  https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior  Hint: you can parse a date string in the format 2/17/2020 using the code below.  This link will tell you what things like `%m` and `%Y` mean.\n",
    "\n",
    "```\n",
    "from datetime import datetime\n",
    "d = datetime.strptime('2/17/2020', '%m/%d/%Y')\n",
    "```\n",
    "\n",
    "If you want to take this another step, **create a list of tuples that contain (observate date, total confirmed) totalled over all locations represented in the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total confirmed cases in all of Mainland China: 24408\n"
     ]
    }
   ],
   "source": [
    "#1 - Caclulate the total confirmed cases in all of Mainland China as of the latest information in the data set\n",
    "# Because the # of confirmed cases is accumulative, the maximum # for each province is the latest # of cases\n",
    "import csv\n",
    "with open('2019_nCoV_20200121_20200206.csv') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    province_cases = {}\n",
    "    for row in csv_reader:\n",
    "        if row[1] == 'Mainland China':\n",
    "            if row[3] != '':\n",
    "                case_n = int((row[3]))\n",
    "            if row[0] not in province_cases.keys() or province_cases[row[0]] < case_n:\n",
    "                province_cases[row[0]] = case_n\n",
    "case_total = 0\n",
    "for province, number in province_cases.items():\n",
    "    case_total += number\n",
    "    \n",
    "print(\"Total confirmed cases in all of Mainland China: \" + str(case_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2020, 2, 5, 0, 0), 24308),\n",
       " (datetime.datetime(2020, 2, 4, 0, 0), 20452),\n",
       " (datetime.datetime(2020, 2, 1, 0, 0), 11860),\n",
       " (datetime.datetime(2020, 2, 3, 0, 0), 17241),\n",
       " (datetime.datetime(2020, 2, 2, 0, 0), 16556),\n",
       " (datetime.datetime(2020, 1, 31, 0, 0), 9783),\n",
       " (datetime.datetime(2020, 1, 30, 0, 0), 8124),\n",
       " (datetime.datetime(2020, 1, 29, 0, 0), 6071),\n",
       " (datetime.datetime(2020, 1, 28, 0, 0), 4610),\n",
       " (datetime.datetime(2020, 1, 27, 0, 0), 2825),\n",
       " (datetime.datetime(2020, 1, 26, 0, 0), 2062),\n",
       " (datetime.datetime(2020, 1, 25, 0, 0), 1320),\n",
       " (datetime.datetime(2020, 1, 24, 0, 0), 865),\n",
       " (datetime.datetime(2020, 1, 23, 0, 0), 639),\n",
       " (datetime.datetime(2020, 1, 22, 0, 0), 547),\n",
       " (datetime.datetime(2020, 1, 21, 0, 0), 326)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 -  Create a list of tuples that contain (observate date, total confirmed) totalled over all locations represented in the data\n",
    "# Step-1. Create a disctionary of # of cases for each combination of date and province\n",
    "import csv\n",
    "from datetime import datetime\n",
    "with open('2019_nCoV_20200121_20200206.csv') as f:\n",
    "    next(f)\n",
    "    csv_reader = csv.reader(f)\n",
    "    province_cases = {}\n",
    "    for row in csv_reader:\n",
    "        year = row[2].split(' ')[0].split('/')[2]\n",
    "        if len(year) == 2:\n",
    "            date_str = row[2].split(' ')[0]+'20'\n",
    "        else:\n",
    "            date_str = row[2].split(' ')[0]\n",
    "        if row[1] == 'Mainland China':\n",
    "            date = datetime.strptime(date_str, '%m/%d/%Y')\n",
    "            if row[3] != '':\n",
    "                case_n = int((row[3]))\n",
    "            else:\n",
    "                case_n = 0 \n",
    "            province = row[0]\n",
    "            key_list = [date, province]\n",
    "            key_tuple = tuple(key_list)\n",
    "            province_cases[key_tuple] = case_n\n",
    "\n",
    "# Step-2. Create a list of tuples including # of aggregated cases for each date\n",
    "date_cases_dict = {}\n",
    "for key, value in province_cases.items():\n",
    "    date = key[0]\n",
    "    if date in date_cases_dict.keys():\n",
    "        date_cases_dict[date] += value\n",
    "    else:\n",
    "        date_cases_dict[date] = value\n",
    "date_cases_list = []\n",
    "for key, value in date_cases_dict.items():\n",
    "    case_list = [key, value]\n",
    "    case_tuple = tuple(case_list)\n",
    "    date_cases_list.append(case_tuple)\n",
    "date_cases_list  \n",
    "# The # for each date may not contain all provinces because one province may not report on every date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submitting Your Work\n",
    "\n",
    "In order to submit your work, you'll need to use the `git` command line program to **add** your homework file (this file) to your local repository, **commit** your changes to your local repository, and then **push** those changes up to github.com.  From there, I'll be able to **pull** the changes down and do my grading.  I'll provide some feedback, **commit** and **push** my comments back to you.  Next week, I'll show you how to **pull** down my comments.\n",
    "\n",
    "To run through everything one last time and submit your work:\n",
    "1. Use the `Kernel` -> `Restart Kernel and Run All Cells` menu option to run everything from top to bottom and stop here.\n",
    "2. Save this note with Ctrl-S (or Cmd-S)\n",
    "2. Skip down to the last command cell (the one starting with `%%bash`) and run that cell.\n",
    "\n",
    "If anything fails along the way with this submission part of the process, let me know.  I'll help you troubleshoort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "DO NOT REMOVE THIS LINE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-cef8011cb395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DO NOT REMOVE THIS LINE\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: DO NOT REMOVE THIS LINE"
     ]
    }
   ],
   "source": [
    "assert False, \"DO NOT REMOVE THIS LINE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Untracked files:\n",
      "\t../week02/week02_inclass.ipynb\n",
      "\t../week04/week04_lookups.ipynb\n",
      "\t../week05_assignment_2.ipynb\n",
      "\t2019_nCoV_20200121_20200206.csv\n",
      "\tallergies.json\n",
      "\toutput.csv\n",
      "\tweek06_assignment_2copy.ipynb\n",
      "\n",
      "nothing added to commit but untracked files present\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git pull\n",
    "git add week06_assignment_2.ipynb\n",
    "git commit -a -m \"Submitting the week 6 programming assignment\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "If the message above says something like _Submitting the week 6 programming assignment_ or _Everything is up to date_, then your work was submitted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
